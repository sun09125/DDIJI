#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import urllib.request
import urllib.parse
import re
import json
import time
import os

class BackCoverScraper:
    def __init__(self, download_dir="back_covers"):
        """
        ë’·í‘œì§€ ì´ë¯¸ì§€ ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
        """
        self.download_dir = download_dir
        os.makedirs(download_dir, exist_ok=True)

        # User-Agent ì„¤ì •
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }

    def get_product_page_html(self, product_url):
        """
        ìƒí’ˆ ìƒì„¸ í˜ì´ì§€ HTML ê°€ì ¸ì˜¤ê¸°
        """
        try:
            request = urllib.request.Request(product_url, headers=self.headers)
            with urllib.request.urlopen(request, timeout=15) as response:
                html = response.read().decode('utf-8', errors='ignore')
            return html
        except Exception as e:
            print(f"í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def extract_additional_images(self, html, book_title=""):
        """
        ìƒí’ˆ í˜ì´ì§€ì—ì„œ ì¶”ê°€ ì´ë¯¸ì§€ URL ì¶”ì¶œ
        """
        if not html:
            return []

        image_urls = []

        # ë‹¤ì–‘í•œ ì´ë¯¸ì§€ íŒ¨í„´ ê²€ìƒ‰
        patterns = [
            # ìƒí’ˆ ì´ë¯¸ì§€ ê°¤ëŸ¬ë¦¬
            r'src=["\']([^"\']*product[^"\']*\.jpg)["\']',
            r'src=["\']([^"\']*cover[^"\']*\.jpg)["\']',
            # ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€
            r'data-src=["\']([^"\']*\.jpg)["\']',
            # ì´ë¯¸ì§€ íƒœê·¸ ë‚´ì˜ ëª¨ë“  jpg íŒŒì¼
            r'<img[^>]*src=["\']([^"\']*\.jpg)["\'][^>]*>',
            # ë°±ê·¸ë¼ìš´ë“œ ì´ë¯¸ì§€
            r'background-image:\s*url\(["\']?([^"\']*\.jpg)["\']?\)',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, html, re.IGNORECASE)
            for match in matches:
                if match not in image_urls and 'aladin.co.kr' in match:
                    image_urls.append(match)

        print(f"  ğŸ“· ë°œê²¬ëœ ì´ë¯¸ì§€: {len(image_urls)}ê°œ")
        return image_urls

    def download_image(self, image_url, filename):
        """
        ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        """
        try:
            request = urllib.request.Request(image_url, headers=self.headers)
            with urllib.request.urlopen(request, timeout=15) as response:
                image_data = response.read()

            file_path = os.path.join(self.download_dir, filename)
            with open(file_path, 'wb') as f:
                f.write(image_data)

            print(f"    âœ… ë‹¤ìš´ë¡œë“œ: {filename} ({len(image_data):,} bytes)")
            return True

        except Exception as e:
            print(f"    âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def scrape_book_images(self, book_info):
        """
        íŠ¹ì • ë„ì„œì˜ ëª¨ë“  ì´ë¯¸ì§€ ìˆ˜ì§‘
        """
        title = book_info.get('title', '').strip()
        author = book_info.get('author', '').strip()
        product_url = book_info.get('link', '')
        isbn13 = book_info.get('isbn13', '') or book_info.get('isbn', '')
        rank = book_info.get('bestRank', 0)

        print(f"\nğŸ” [{rank}ìœ„] {title} - {author}")
        print(f"  ğŸ“– ìƒí’ˆ í˜ì´ì§€: {product_url}")

        if not product_url:
            print("  âš ï¸  ìƒí’ˆ URLì´ ì—†ìŠµë‹ˆë‹¤.")
            return 0

        # ìƒí’ˆ í˜ì´ì§€ HTML ê°€ì ¸ì˜¤ê¸°
        html = self.get_product_page_html(product_url)
        if not html:
            return 0

        # ì¶”ê°€ ì´ë¯¸ì§€ URL ì¶”ì¶œ
        image_urls = self.extract_additional_images(html, title)

        if not image_urls:
            print("  âš ï¸  ì¶”ê°€ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return 0

        # íŒŒì¼ëª… ìƒì„±ìš© ì•ˆì „í•œ ë¬¸ìì—´
        safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).strip()[:20]
        safe_author = "".join(c for c in author if c.isalnum() or c in (' ', '-', '_')).strip()[:15]

        download_count = 0

        # ê° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        for i, img_url in enumerate(image_urls[:5], 1):  # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ
            # ì ˆëŒ€ URLë¡œ ë³€í™˜
            if img_url.startswith('//'):
                img_url = 'https:' + img_url
            elif img_url.startswith('/'):
                img_url = 'https://www.aladin.co.kr' + img_url
            elif not img_url.startswith('http'):
                continue

            filename = f"{rank:03d}_{isbn13}_{safe_title}_{safe_author}_img{i}.jpg"

            if self.download_image(img_url, filename):
                download_count += 1

            time.sleep(0.5)  # ìš”ì²­ ê°„ ëŒ€ê¸°

        return download_count


def test_back_cover_scraping():
    """
    ë’·í‘œì§€ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ (TOP 3 ë² ìŠ¤íŠ¸ì…€ëŸ¬)
    """
    # í…ŒìŠ¤íŠ¸ìš© ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì •ë³´
    test_books = [
        {
            'title': 'ì ˆì°½',
            'author': 'êµ¬ë³‘ëª¨',
            'link': 'https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=371723601',
            'isbn13': '9791141602451',
            'bestRank': 1
        },
        {
            'title': 'ì•„ë¬´ë„ ì˜¤ì§€ ì•ŠëŠ” ê³³ì—ì„œ',
            'author': 'ì²œì„ ë€',
            'link': 'https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=374258051',
            'isbn13': '9791193078709',
            'bestRank': 2
        },
        {
            'title': 'í˜¼ëª¨ë…¸',
            'author': 'ì„±í•´ë‚˜',
            'link': 'https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=361016676',
            'isbn13': '9788936439743',
            'bestRank': 3
        }
    ]

    scraper = BackCoverScraper("back_covers_test")

    print("ğŸ” ë’·í‘œì§€ ë° ì¶”ê°€ ì´ë¯¸ì§€ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    total_images = 0

    for book in test_books:
        images_downloaded = scraper.scrape_book_images(book)
        total_images += images_downloaded
        time.sleep(2)  # í˜ì´ì§€ ê°„ ëŒ€ê¸°

    print(f"\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ì´ {total_images}ê°œ ì¶”ê°€ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ")


if __name__ == "__main__":
    test_back_cover_scraping()